{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94df408",
   "metadata": {},
   "source": [
    "## Baseline Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc9c59a",
   "metadata": {},
   "source": [
    "This file is to develop a basic model for establishing a baseline classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6236b6",
   "metadata": {},
   "source": [
    "##### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "047f2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa7742",
   "metadata": {},
   "source": [
    "##### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5841bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('data.pt')\n",
    "X = data['features']\n",
    "y = data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bea2cf",
   "metadata": {},
   "source": [
    "##### 2. Split between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2801f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187ac73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([629, 60660])\n",
      "y_train torch.Size([310])\n",
      "\n",
      "X_test: torch.Size([310, 60660])\n",
      "y_test: torch.Size([310])\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('y_train', y_test.shape)\n",
    "print()\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c8b0f",
   "metadata": {},
   "source": [
    "##### 3. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e688e",
   "metadata": {},
   "source": [
    "Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d950c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b625258",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a59b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1000\n",
    "selector = SelectKBest(k=k, score_func=mutual_info_classif)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_test = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271870ee",
   "metadata": {},
   "source": [
    "##### 4. Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de185b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: C=0.01 penalty=l1\n",
      "Model: C=0.01 penalty=l2\n",
      "Model: C=0.1 penalty=l1\n",
      "Model: C=0.1 penalty=l2\n",
      "Model: C=1 penalty=l1\n",
      "Model: C=1 penalty=l2\n",
      "Model: C=10 penalty=l1\n",
      "Model: C=10 penalty=l2\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.01, 0.1, 1, 10]\n",
    "penalties = ['l1', 'l2']\n",
    "\n",
    "models = []\n",
    "\n",
    "for C in Cs:\n",
    "    for penalty in penalties:\n",
    "        print(f'Model: C={C} penalty={penalty}')\n",
    "        #\n",
    "        # Define the model\n",
    "        #\n",
    "        model = LogisticRegression(solver='saga', \n",
    "                                   max_iter=10000,\n",
    "                                   class_weight='balanced',\n",
    "                                   C=C,\n",
    "                                   penalty=penalty)\n",
    "        #\n",
    "        # Fit\n",
    "        #\n",
    "        model.fit(X_train, y_train)\n",
    "        #\n",
    "        # Save\n",
    "        #\n",
    "        models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed913f",
   "metadata": {},
   "source": [
    "##### 5. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86efb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds, y_test_preds = [], []\n",
    "for model in models:\n",
    "    y_train_preds.append(model.predict(X_train))\n",
    "    y_test_preds.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f612cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> C=0.01 penalty=l1\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88       415\n",
      "         1.0       0.78      0.73      0.76       214\n",
      "\n",
      "    accuracy                           0.84       629\n",
      "   macro avg       0.82      0.81      0.82       629\n",
      "weighted avg       0.84      0.84      0.84       629\n",
      "\n",
      "[[371  44]\n",
      " [ 57 157]]\n",
      "\n",
      "ROC AUC: 0.9035131178921293\n",
      "\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.87       211\n",
      "         1.0       0.70      0.83      0.76        99\n",
      "\n",
      "    accuracy                           0.83       310\n",
      "   macro avg       0.81      0.83      0.82       310\n",
      "weighted avg       0.84      0.83      0.84       310\n",
      "\n",
      "[[176  35]\n",
      " [ 17  82]]\n",
      "\n",
      "ROC AUC: 0.921585523481258\n",
      "\n",
      "\n",
      "--> C=0.01 penalty=l2\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96       415\n",
      "         1.0       0.91      0.94      0.92       214\n",
      "\n",
      "    accuracy                           0.95       629\n",
      "   macro avg       0.94      0.95      0.94       629\n",
      "weighted avg       0.95      0.95      0.95       629\n",
      "\n",
      "[[394  21]\n",
      " [ 12 202]]\n",
      "\n",
      "ROC AUC: 0.9902488458506925\n",
      "\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90       211\n",
      "         1.0       0.75      0.86      0.80        99\n",
      "\n",
      "    accuracy                           0.86       310\n",
      "   macro avg       0.84      0.86      0.85       310\n",
      "weighted avg       0.87      0.86      0.87       310\n",
      "\n",
      "[[183  28]\n",
      " [ 14  85]]\n",
      "\n",
      "ROC AUC: 0.9267078366604433\n",
      "\n",
      "\n",
      "--> C=0.1 penalty=l1\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93       415\n",
      "         1.0       0.84      0.90      0.87       214\n",
      "\n",
      "    accuracy                           0.91       629\n",
      "   macro avg       0.89      0.91      0.90       629\n",
      "weighted avg       0.91      0.91      0.91       629\n",
      "\n",
      "[[379  36]\n",
      " [ 22 192]]\n",
      "\n",
      "ROC AUC: 0.9656457606125435\n",
      "\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.86      0.89       211\n",
      "         1.0       0.74      0.86      0.79        99\n",
      "\n",
      "    accuracy                           0.86       310\n",
      "   macro avg       0.83      0.86      0.84       310\n",
      "weighted avg       0.87      0.86      0.86       310\n",
      "\n",
      "[[181  30]\n",
      " [ 14  85]]\n",
      "\n",
      "ROC AUC: 0.9292450572071425\n",
      "\n",
      "\n",
      "--> C=0.1 penalty=l2\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       415\n",
      "         1.0       1.00      1.00      1.00       214\n",
      "\n",
      "    accuracy                           1.00       629\n",
      "   macro avg       1.00      1.00      1.00       629\n",
      "weighted avg       1.00      1.00      1.00       629\n",
      "\n",
      "[[414   1]\n",
      " [  0 214]]\n",
      "\n",
      "ROC AUC: 0.999977480013512\n",
      "\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90       211\n",
      "         1.0       0.76      0.86      0.81        99\n",
      "\n",
      "    accuracy                           0.87       310\n",
      "   macro avg       0.84      0.87      0.85       310\n",
      "weighted avg       0.87      0.87      0.87       310\n",
      "\n",
      "[[184  27]\n",
      " [ 14  85]]\n",
      "\n",
      "ROC AUC: 0.915793001101058\n",
      "\n",
      "\n",
      "--> C=1 penalty=l1\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       415\n",
      "         1.0       1.00      1.00      1.00       214\n",
      "\n",
      "    accuracy                           1.00       629\n",
      "   macro avg       1.00      1.00      1.00       629\n",
      "weighted avg       1.00      1.00      1.00       629\n",
      "\n",
      "[[415   0]\n",
      " [  0 214]]\n",
      "\n",
      "ROC AUC: 1.0\n",
      "\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.86      0.88       211\n",
      "         1.0       0.73      0.78      0.75        99\n",
      "\n",
      "    accuracy                           0.84       310\n",
      "   macro avg       0.81      0.82      0.81       310\n",
      "weighted avg       0.84      0.84      0.84       310\n",
      "\n",
      "[[182  29]\n",
      " [ 22  77]]\n",
      "\n",
      "ROC AUC: 0.9099526066350712\n",
      "\n",
      "\n",
      "--> C=1 penalty=l2\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       415\n",
      "         1.0       1.00      1.00      1.00       214\n",
      "\n",
      "    accuracy                           1.00       629\n",
      "   macro avg       1.00      1.00      1.00       629\n",
      "weighted avg       1.00      1.00      1.00       629\n",
      "\n",
      "[[415   0]\n",
      " [  0 214]]\n",
      "\n",
      "ROC AUC: 1.0\n",
      "\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.85      0.89       211\n",
      "         1.0       0.73      0.86      0.79        99\n",
      "\n",
      "    accuracy                           0.85       310\n",
      "   macro avg       0.83      0.86      0.84       310\n",
      "weighted avg       0.87      0.85      0.86       310\n",
      "\n",
      "[[180  31]\n",
      " [ 14  85]]\n",
      "\n",
      "ROC AUC: 0.9072238977452247\n",
      "\n",
      "\n",
      "--> C=10 penalty=l1\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       415\n",
      "         1.0       1.00      1.00      1.00       214\n",
      "\n",
      "    accuracy                           1.00       629\n",
      "   macro avg       1.00      1.00      1.00       629\n",
      "weighted avg       1.00      1.00      1.00       629\n",
      "\n",
      "[[415   0]\n",
      " [  0 214]]\n",
      "\n",
      "ROC AUC: 1.0\n",
      "\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.86      0.89       211\n",
      "         1.0       0.73      0.84      0.78        99\n",
      "\n",
      "    accuracy                           0.85       310\n",
      "   macro avg       0.83      0.85      0.84       310\n",
      "weighted avg       0.86      0.85      0.85       310\n",
      "\n",
      "[[181  30]\n",
      " [ 16  83]]\n",
      "\n",
      "ROC AUC: 0.9040164679975107\n",
      "\n",
      "\n",
      "--> C=10 penalty=l2\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       415\n",
      "         1.0       1.00      1.00      1.00       214\n",
      "\n",
      "    accuracy                           1.00       629\n",
      "   macro avg       1.00      1.00      1.00       629\n",
      "weighted avg       1.00      1.00      1.00       629\n",
      "\n",
      "[[415   0]\n",
      " [  0 214]]\n",
      "\n",
      "ROC AUC: 1.0\n",
      "\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.86      0.89       211\n",
      "         1.0       0.74      0.86      0.79        99\n",
      "\n",
      "    accuracy                           0.86       310\n",
      "   macro avg       0.83      0.86      0.84       310\n",
      "weighted avg       0.87      0.86      0.86       310\n",
      "\n",
      "[[181  30]\n",
      " [ 14  85]]\n",
      "\n",
      "ROC AUC: 0.9043515725980181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (model, y_train_pred, y_test_pred) in enumerate(zip(models, y_train_preds, y_test_preds)):\n",
    "    params = model.get_params()\n",
    "    print()\n",
    "    print(f\"--> C={params['C']} penalty={params['penalty']}\")\n",
    "    print('Train:')\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print()\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]))\n",
    "    print()\n",
    "    print()\n",
    "    print('Test:')\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print()\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd523a",
   "metadata": {},
   "source": [
    "Evaluation results:\n",
    "| C | penalty | precision | recall | f1-score | ROC |\n",
    "|---|---------|-----------|--------|----------|-----|\n",
    "| 0.01 | l1 | 0.70 | 0.83 | 0.76 | 0.921 |\n",
    "| 0.01 | l2 | 0.75 | 0.86 | 0.80 | 0.926 |\n",
    "| 0.1 | l1 | 0.74 | 0.86 | 0.79 | 0.929 |\n",
    "| 0.1 | l2 | 0.76 | 0.86 | 0.81 | 0.916 |\n",
    "| 1 | l1 | 0.73 | 0.78 | 0.75 | 0.910 |\n",
    "| 1 | l2 | 0.73 | 0.86 | 0.79 | 0.907 |\n",
    "| 10 | l1 | 0.73 | 0.84 | 0.78 | 0.904 |\n",
    "| 10 | l2 | 0.74 | 0.86 | 0.79 | 0.904 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b132ddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'class_weight': 'balanced',\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 10000,\n",
       " 'multi_class': 'deprecated',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l1',\n",
       " 'random_state': None,\n",
       " 'solver': 'saga',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = [model for model in models if model.get_params()['C'] == 0.1 and model.get_params()['penalty'] == 'l1'][0]\n",
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20277b",
   "metadata": {},
   "source": [
    "##### 5. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8a45b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mapping\n",
    "import pickle\n",
    "with open('baseline_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb157da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
